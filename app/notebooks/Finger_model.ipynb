{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mneZ1RzbrDvd",
        "outputId": "1e67d131-2294-4232-d4e0-d17056de5df0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'VQShape' already exists and is not an empty directory.\n",
            "/content/VQShape\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/YunshiWen/VQShape.git\n",
        "%cd VQShape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBcj2imqsk8e"
      },
      "outputs": [],
      "source": [
        "!pip install lightning\n",
        "!pip install sktime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xc1uTMK9rizn"
      },
      "outputs": [],
      "source": [
        "from vqshape.pretrain import LitVQShape\n",
        "import torch\n",
        "\n",
        "checkpoint = \"checkpoints/uea_dim256_codebook512/VQShape.ckpt\"\n",
        "lit = LitVQShape.load_from_checkpoint(checkpoint, map_location=\"cuda\")\n",
        "base_model = lit.model\n",
        "base_model.eval()\n",
        "\n",
        "for p in base_model.parameters():\n",
        "    p.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GiHJuAwvvgeE"
      },
      "outputs": [],
      "source": [
        "from sktime.datasets import load_from_tsfile\n",
        "import numpy as np\n",
        "\n",
        "X_train, y_train = load_from_tsfile(\"/content/FingerMovements_TRAIN.ts\", return_data_type=\"numpy3D\")\n",
        "X_test, y_test   = load_from_tsfile(\"/content/FingerMovements_TEST.ts\",  return_data_type=\"numpy3D\")\n",
        "\n",
        "label_map = {\"left\": 0, \"right\": 1}\n",
        "y_train = np.array([label_map[y] for y in y_train])\n",
        "y_test  = np.array([label_map[y] for y in y_test])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4_G7eD10QVG"
      },
      "outputs": [],
      "source": [
        "print(base_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQNNvA5yGbD3",
        "outputId": "edca26bc-3e0f-496c-bffb-75ee47369bc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Paso 1: Calculando Features ---\n",
            "Calculando 316 histogramas...\n",
            "Calculando 100 histogramas...\n",
            "Features calculados.\n",
            "\n",
            "--- Paso 2: Iniciando entrenamiento optimizado ---\n",
            "Epoch 001 | Train Acc: 0.506 | Test Acc: 0.510 (¡Nuevo Mejor!)\n",
            "Epoch 010 | Train Acc: 0.630 | Test Acc: 0.510\n",
            "Epoch 020 | Train Acc: 0.684 | Test Acc: 0.540\n",
            "Epoch 030 | Train Acc: 0.680 | Test Acc: 0.520\n",
            "Epoch 040 | Train Acc: 0.703 | Test Acc: 0.490\n",
            "Parando temprano por falta de mejora.\n",
            "\n",
            "Entrenamiento finalizado.\n",
            "Mejor Test Accuracy: 0.590 (en época 9)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau # Importamos el scheduler\n",
        "import numpy as np\n",
        "import copy # Para guardar el mejor modelo\n",
        "\n",
        "# --- (Asegúrate de tener tus funciones `preprocess_signal` y `get_histogram` definidas) ---\n",
        "# ... (preprocess_signal y get_histogram van aquí) ...\n",
        "\n",
        "# --- 1. Pre-calcula TODOS los histogramas (sin cambios) ---\n",
        "print(\"--- Paso 1: Calculando Features ---\")\n",
        "H_train = get_features(X_train)\n",
        "H_test  = get_features(X_test)\n",
        "y_train_tensor = torch.tensor(y_train).long().cuda()\n",
        "y_test_tensor  = torch.tensor(y_test).long().cuda()\n",
        "print(\"Features calculados.\")\n",
        "\n",
        "# --- 2. Define el Clasificador (sin cambios) ---\n",
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self, hist_dim=512):\n",
        "        super().__init__()\n",
        "        self.net = nn.Linear(hist_dim, 2)\n",
        "\n",
        "    def forward(self, h):\n",
        "        return self.net(h)\n",
        "\n",
        "clf = SimpleClassifier(hist_dim=512).cuda()\n",
        "\n",
        "# --- 3. Define Optimizador y Scheduler (¡AJUSTES CLAVE!) ---\n",
        "# El repo usa weight_decay=1e-5 y lr=1e-3\n",
        "optimizer = torch.optim.Adam(clf.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Usamos un scheduler para reducir el LR si el test_acc deja de mejorar\n",
        "# Esto ayuda a \"afinar\" el modelo y evitar sobreajuste\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10)\n",
        "\n",
        "# --- 4. DataLoaders (sin cambios) ---\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = TensorDataset(H_train, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataset = TensorDataset(H_test, y_test_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# --- 5. Bucle de Entrenamiento con Early Stopping y Scheduler ---\n",
        "print(\"\\n--- Paso 2: Iniciando entrenamiento optimizado ---\")\n",
        "\n",
        "# Variables para guardar el mejor modelo\n",
        "best_test_acc = 0.0\n",
        "best_epoch = 0\n",
        "best_model_state = None # Guardaremos los \"pesos\" del mejor modelo\n",
        "MAX_EPOCHS = 150 # Más épocas\n",
        "\n",
        "for epoch in range(MAX_EPOCHS):\n",
        "    clf.train()\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    for h_batch, y_batch in train_loader:\n",
        "        logits = clf(h_batch)\n",
        "        loss = criterion(logits, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = logits.argmax(1)\n",
        "        train_correct += (preds == y_batch).sum().item()\n",
        "        train_total += y_batch.size(0)\n",
        "\n",
        "    train_acc = train_correct / train_total\n",
        "\n",
        "    # --- Bucle de Evaluación (Validación) ---\n",
        "    clf.eval()\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    with torch.no_grad():\n",
        "        for h_batch, y_batch in test_loader:\n",
        "            logits = clf(h_batch)\n",
        "            preds = logits.argmax(1)\n",
        "            test_correct += (preds == y_batch).sum().item()\n",
        "            test_total += y_batch.size(0)\n",
        "\n",
        "    test_acc = test_correct / test_total\n",
        "\n",
        "    # --- Lógica de Early Stopping y Scheduler ---\n",
        "\n",
        "    # El scheduler se alimenta con el accuracy de test\n",
        "    scheduler.step(test_acc)\n",
        "\n",
        "    if test_acc > best_test_acc:\n",
        "        best_test_acc = test_acc\n",
        "        best_epoch = epoch\n",
        "        best_model_state = copy.deepcopy(clf.state_dict()) # Guarda una copia de los pesos\n",
        "\n",
        "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "             print(f\"Epoch {epoch+1:03d} | Train Acc: {train_acc:.3f} | Test Acc: {test_acc:.3f} (¡Nuevo Mejor!)\")\n",
        "    else:\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "             print(f\"Epoch {epoch+1:03d} | Train Acc: {train_acc:.3f} | Test Acc: {test_acc:.3f}\")\n",
        "\n",
        "    # Parada temprana si no mejora en 30 épocas\n",
        "    if (epoch - best_epoch) > 30:\n",
        "        print(\"Parando temprano por falta de mejora.\")\n",
        "        break\n",
        "\n",
        "print(f\"\\nEntrenamiento finalizado.\")\n",
        "print(f\"Mejor Test Accuracy: {best_test_acc:.3f} (en época {best_epoch+1})\")\n",
        "\n",
        "# Carga los mejores pesos en el modelo\n",
        "if best_model_state:\n",
        "    clf.load_state_dict(best_model_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqcp3wR3sV9v",
        "outputId": "ea1a1fdf-d989-4700-c507-9ad1a5bd0431"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo guardado como best_eeg_classifier.pt\n"
          ]
        }
      ],
      "source": [
        "# --- Guardar el mejor modelo ---\n",
        "torch.save(best_model_state, \"best_eeg_classifier.pt\")\n",
        "print(\"Modelo guardado como best_eeg_classifier.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_atjnpJNPKu",
        "outputId": "3f981384-c069-4013-cae2-46877b0415e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SimpleClassifier(\n",
              "  (net): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf = SimpleClassifier(hist_dim=512).cuda()\n",
        "clf.load_state_dict(torch.load(\"best_eeg_classifier.pt\"))\n",
        "clf.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87_a4qtENRLY",
        "outputId": "3e88b132-4c6a-4c83-d157-aad8736a0fa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicción: right\n",
            "Etiqueta real: right\n"
          ]
        }
      ],
      "source": [
        "i = 0   # índice\n",
        "\n",
        "with torch.no_grad():\n",
        "    x = preprocess_signal(X_test[i])\n",
        "    hist = get_histogram(x)\n",
        "    pred = clf(hist.unsqueeze(0)).argmax(1).item()\n",
        "\n",
        "print(\"Predicción:\", \"right\" if pred == 1 else \"left\")\n",
        "print(\"Etiqueta real:\", \"right\" if y_test[i] == 1 else \"left\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
